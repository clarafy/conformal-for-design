{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has the script for reproducing the experimental results shown in Fig. 3, 4, S2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from importlib import reload\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import numpy as np\n",
    "    \n",
    "import assay\n",
    "import calibrate as cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 92 order-2 features\n",
      "Loading estimated measurement noise SD computed using order 7 and significance level 0.01\n",
      "red, 384, 6. 100 trials. SCS, FCS coverage: 0.8800, 0.8600. 752.7 s\n",
      "red, 384, 6. 200 trials. SCS, FCS coverage: 0.9050, 0.8950. 1523.3 s\n",
      "red, 384, 6. 300 trials. SCS, FCS coverage: 0.9100, 0.9000. 2321.2 s\n",
      "red, 384, 6. 400 trials. SCS, FCS coverage: 0.9050, 0.8975. 3115.3 s\n",
      "red, 384, 6. 500 trials. SCS, FCS coverage: 0.9040, 0.8960. 3886.5 s\n",
      "red, 384, 6. 600 trials. SCS, FCS coverage: 0.9083, 0.8967. 4682.9 s\n",
      "red, 384, 6. 700 trials. SCS, FCS coverage: 0.9129, 0.9014. 5508.1 s\n",
      "red, 384, 6. 800 trials. SCS, FCS coverage: 0.9100, 0.9012. 6339.8 s\n",
      "red, 384, 6. 900 trials. SCS, FCS coverage: 0.9156, 0.9056. 7130.1 s\n",
      "red, 384, 6. 1000 trials. SCS, FCS coverage: 0.9170, 0.9060. 7918.1 s\n",
      "red, 384, 6. 1100 trials. SCS, FCS coverage: 0.9182, 0.9082. 8694.7 s\n",
      "red, 384, 6. 1200 trials. SCS, FCS coverage: 0.9183, 0.9092. 9461.5 s\n",
      "red, 384, 6. 1300 trials. SCS, FCS coverage: 0.9192, 0.9092. 10214.7 s\n",
      "red, 384, 6. 1400 trials. SCS, FCS coverage: 0.9207, 0.9107. 10968.0 s\n",
      "red, 384, 6. 1500 trials. SCS, FCS coverage: 0.9233, 0.9140. 11721.7 s\n",
      "red, 384, 6. 1600 trials. SCS, FCS coverage: 0.9237, 0.9144. 12484.3 s\n",
      "red, 384, 6. 1700 trials. SCS, FCS coverage: 0.9259, 0.9165. 13244.3 s\n",
      "red, 384, 6. 1800 trials. SCS, FCS coverage: 0.9244, 0.9150. 13986.6 s\n",
      "red, 384, 6. 1900 trials. SCS, FCS coverage: 0.9253, 0.9163. 14725.1 s\n",
      "red, 384, 6. 2000 trials. SCS, FCS coverage: 0.9270, 0.9160. 15472.0 s\n"
     ]
    }
   ],
   "source": [
    "reload(cal)\n",
    "reload(assay)\n",
    "\n",
    "alpha = 0.1                           # miscoverage\n",
    "n_trains = [96, 192, 384]             # number of training points\n",
    "ntrain2reg = {96: 10, 192: 1, 384: 1} # ridge regularization strength (gamma in code and paper)\n",
    "n_seed = 2000                         # number of random trials\n",
    "lmbdas = [0, 2, 4, 6]                 # lambda, inverse temperature\n",
    "y_increment = 0.02                    # grid spacing between candidate label values, \\Delta in paper\n",
    "ys = np.arange(0, 2.21, y_increment)  # candidate label values, \\mathcal{Y} in paper\n",
    "order = 2                             # complexity of features. 1 encodes the AA at each site,\n",
    "                                      # 2 the AAs at each pair of sites,\n",
    "                                      # 3 the AAs at each set of 3 sites, etc.\n",
    "        \n",
    "# likelihood under training input distribution, p_X in paper (uniform distribution)\n",
    "ptrain_fn = lambda x: (1.0 / np.power(2, 13)) * np.ones([x.shape[0]])\n",
    "for fitness_str in ['red']:\n",
    "    \n",
    "    # featurize all sequences in combinatorially complete dataset\n",
    "    data = assay.PoelwijkData(fitness_str, order=order)\n",
    "    \n",
    "    for t, n_train in enumerate(n_trains):\n",
    "\n",
    "        reg = ntrain2reg[n_train]\n",
    "        fcs = cal.ConformalRidgeFeedbackCovariateShift(ptrain_fn, ys, data.X_nxp, reg)\n",
    "        scs = cal.ConformalRidgeStandardCovariateShift(ptrain_fn, ys, data.X_nxp, reg)\n",
    "\n",
    "        for l, lmbda in enumerate(lmbdas):\n",
    "\n",
    "            fset_s, sset_s = [], []\n",
    "            fcov_s, scov_s = np.zeros([n_seed]), np.zeros([n_seed])\n",
    "            ytest_s, predtest_s = np.zeros([n_seed]), np.zeros([n_seed])\n",
    "            t0 = time.time()\n",
    "\n",
    "            for seed in range(n_seed):\n",
    "                \n",
    "                # sample training and designed data\n",
    "                Xtrain_nxp, ytrain_n, Xtest_1xp, ytest_1, pred_1 = assay.get_training_and_designed_data(\n",
    "                    data, n_train, reg, lmbda, seed=seed )\n",
    "                ytest_s[seed] = ytest_1[0]\n",
    "                predtest_s[seed] = pred_1[0]\n",
    "\n",
    "                # construct confidence set under feedback covariate shift\n",
    "                fset, _ = fcs.get_confidence_set(Xtrain_nxp, ytrain_n, Xtest_1xp, lmbda, alpha=alpha) \n",
    "                fset_s.append(fset)\n",
    "                fcov_s[seed] = cal.is_covered(ytest_s[seed], fset, y_increment)\n",
    "\n",
    "                # construct confidence set under standard covariate shift\n",
    "                sset, _ = scs.get_confidence_set(Xtrain_nxp, ytrain_n, Xtest_1xp, lmbda, alpha=alpha) \n",
    "                sset_s.append(sset)\n",
    "                scov_s[seed] = cal.is_covered(ytest_s[seed], sset, y_increment)\n",
    "\n",
    "                if (seed + 1) % 100 == 0:\n",
    "                    print(\"{}, {}, {}. {} trials. SCS, FCS coverage: {:.4f}, {:.4f}. {:.1f} s\".format(\n",
    "                        fitness_str, n_train, lmbda, seed + 1,\n",
    "                        np.mean(scov_s[: seed + 1]), np.mean(fcov_s[: seed + 1]), time.time() - t0))\n",
    "\n",
    "            np.savez('../fluorescence/{}_n{}_lambda{}_alpha{}_gamma{}.npz'.format(\n",
    "                fitness_str, n_train, lmbda, alpha, reg),\n",
    "                     ytest_s=ytest_s, predtest_s=predtest_s,\n",
    "                     fset_s=fset_s, fcov_s=fcov_s, sset_s=sset_s, scov_s=scov_s, \n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-2.1.0",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
