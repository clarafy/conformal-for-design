{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook reproduces the fluorescent protein design experiments whose results are shown in Figs. 3, 4, S2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from importlib import reload\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import numpy as np\n",
    "    \n",
    "import assay\n",
    "import calibrate as cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(cal)\n",
    "reload(assay)\n",
    "alpha = 0.1                           # miscoverage\n",
    "n_trains = [96, 192, 384]             # number of training points\n",
    "ntrain2reg = {96: 10, 192: 1, 384: 1} # ridge regularization strength (gamma in code and paper)\n",
    "n_seed = 5000                         # number of random trials\n",
    "lmbdas = [0, 2, 4, 6]                 # lambda, inverse temperature\n",
    "y_increment = 0.01                    # grid spacing between candidate label values, \\Delta in paper\n",
    "ys = np.arange(0, 1.7, y_increment)   # candidate label values, \\mathcal{Y} in paper\n",
    "order = 2                             # complexity of features. 1 encodes the AA at each site,\n",
    "                                      # 2 the AAs at each pair of sites,\n",
    "                                      # 3 the AAs at each set of 3 sites, etc.\n",
    "        \n",
    "# likelihood under training input distribution, p_X in paper (uniform distribution)\n",
    "ptrain_fn = lambda x: (1.0 / np.power(2, 13)) * np.ones([x.shape[0]])\n",
    "for fitness_str in ['blue', 'red']:\n",
    "    \n",
    "    # featurize all sequences in combinatorially complete dataset\n",
    "    data = assay.PoelwijkData(fitness_str, order=order)\n",
    "    \n",
    "    for t, n_train in enumerate(n_trains):\n",
    "\n",
    "        reg = ntrain2reg[n_train]\n",
    "        fcs = cal.ConformalRidgeFeedbackCovariateShift(ptrain_fn, ys, data.X_nxp, reg)\n",
    "        scs = cal.ConformalRidgeStandardCovariateShift(ptrain_fn, ys, data.X_nxp, reg)\n",
    "\n",
    "        for l, lmbda in enumerate(lmbdas):\n",
    "\n",
    "            fset_s, sset_s = [], []\n",
    "            fcov_s, scov_s = np.zeros([n_seed]), np.zeros([n_seed])\n",
    "            ytest_s, predtest_s = np.zeros([n_seed]), np.zeros([n_seed])\n",
    "            t0 = time.time()\n",
    "\n",
    "            for seed in range(n_seed):\n",
    "                \n",
    "                # sample training and designed data\n",
    "                Xtrain_nxp, ytrain_n, Xtest_1xp, ytest_1, pred_1 = cal.get_training_and_designed_data(\n",
    "                    data, n_train, reg, lmbda, seed=seed )\n",
    "                ytest_s[seed] = ytest_1[0]\n",
    "                predtest_s[seed] = pred_1[0]\n",
    "\n",
    "                # construct confidence set under feedback covariate shift\n",
    "                fset, _ = fcs.get_confidence_set(Xtrain_nxp, ytrain_n, Xtest_1xp, lmbda, alpha=alpha) \n",
    "                fset_s.append(fset)\n",
    "                fcov_s[seed] = cal.is_covered(ytest_s[seed], fset, y_increment)\n",
    "\n",
    "                # construct confidence set under standard covariate shift\n",
    "                sset, _ = scs.get_confidence_set(Xtrain_nxp, ytrain_n, Xtest_1xp, lmbda, alpha=alpha) \n",
    "                sset_s.append(sset)\n",
    "                scov_s[seed] = cal.is_covered(ytest_s[seed], sset, y_increment)\n",
    "\n",
    "                if (seed + 1) % 100 == 0:\n",
    "                    print(\"{}, {}, {}. {} trials. SCS, FCS coverage: {:.4f}, {:.4f}. {:.1f} s\".format(\n",
    "                        fitness_str, n_train, lmbda, seed + 1,\n",
    "                        np.mean(scov_s[: seed + 1]), np.mean(fcov_s[: seed + 1]), time.time() - t0))\n",
    "\n",
    "            np.savez('../results/{}_n{}_lambda{}_alpha{}_gamma{}.npz'.format(\n",
    "                fitness_str, n_train, lmbda, alpha, reg),\n",
    "                     ytest_s=ytest_s, predtest_s=predtest_s,\n",
    "                     fset_s=fset_s, fcov_s=fcov_s, sset_s=sset_s, scov_s=scov_s, \n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-2.1.0",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
