{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook reproduces the AAV design experiments whose results are shown in Fig 5.\n",
    "\n",
    "Variable name suffixes in the following cells denote array dimensions, where\n",
    "\n",
    "n: number of calibration and test data points  \n",
    "l: number of values of the inverse temperature, lambda  \n",
    "L: length of sequence  \n",
    "t: number of trials of sampling from test distribution, per lambda  \n",
    "s: number of samples from test distribution  \n",
    "m: number of calibration data points  \n",
    "m1: m + 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clarafy/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/clarafy/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/clarafy/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/clarafy/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/clarafy/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/clarafy/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from importlib import reload\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from tensorflow import keras\n",
    "\n",
    "import assay\n",
    "import calibrate as cal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load held-out data and parameters of test sequence distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000000 held-out test and calibration data points.\n"
     ]
    }
   ],
   "source": [
    "# load held-out data (calibration and test data)\n",
    "d = np.load('../aav/test_and_calibration_data.npz')\n",
    "seq_n = d['seq_n']  # list of strings\n",
    "y_n = d['y_n']      # true fitnesses\n",
    "n = y_n.size\n",
    "print('Loaded {} held-out test and calibration data points.'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load parameters of test sequence distributions\n",
    "d = np.load('../aav/models/constrained_maxent.npz')\n",
    "\n",
    "phitestnuc_lxLxk = d['phitestnuc_lxLxk']\n",
    "# phitestnuc_lxLxk[i] is an (L, k) numpy array of unnormalized probabilities of a categorical distribution\n",
    "# over k = 4 nucleotides at each of L sequence positions,\n",
    "# corresponding to phi in Eq. 5 of Supp. Materials and Methods here:\n",
    "# https://www.biorxiv.org/content/10.1101/2021.11.02.467003v2.full\n",
    "\n",
    "lambda_l = 1 / d['temperature_l']\n",
    "# note that lambda in bioRxiv above corresponds to 1 / lambda for us\n",
    "\n",
    "meanpredfit_l = d['meanpredfit_l']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct confidence sets for designed sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute predictions and scores for all held-out data (calibration and test data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/clarafy/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/clarafy/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/clarafy/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:Output lambda_3 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to lambda_3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clarafy/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/core.py:895: UserWarning: aav.modeling is not loaded, but a Lambda layer uses it. It may cause errors.\n",
      "  , UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/clarafy/anaconda3/envs/tf-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:Output lambda_4 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to lambda_4.\n",
      "WARNING:tensorflow:Output lambda_5 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to lambda_5.\n"
     ]
    }
   ],
   "source": [
    "n_model = 3\n",
    "datagen = assay.DataGenerator(seq_n)\n",
    "pred_n = np.zeros([n])\n",
    "\n",
    "# load ensemble of trained NNs and take their average prediction for all held-out sequences\n",
    "for seed in range(n_model):\n",
    "    model = keras.models.load_model('../aav/models/h100_seed{}.npy'.format(seed))\n",
    "    pred_n += model.predict_generator(datagen).reshape(n)\n",
    "pred_n /= n_model\n",
    "score_n = np.abs(pred_n - y_n)  # score with residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use rejection sampling to sample from test distribution, and construct confidence sets for resulting designed sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test distribution with lambda = 1.0\n",
      "  On trial 0, sampled 8646 sequences from the test distribution.\n"
     ]
    }
   ],
   "source": [
    "n_trial = 100\n",
    "alpha = 0.1\n",
    "n_cal = 10000\n",
    "\n",
    "# compute training likelihoods of all sequences\n",
    "logptrain_n = assay.get_loglikelihood(seq_n, assay.PNNKAA_LXK)\n",
    "\n",
    "n_lambda = phitestnuc_lxLxk.shape[0]\n",
    "cov_lxt = np.zeros([n_lambda, n_trial])\n",
    "avglen_lxt = np.zeros([n_lambda, n_trial])\n",
    "len_lxt = {(l, t): None for l, t in zip(range(n_lambda), range(n_trial))}\n",
    "fit_lxt = {(l, t): None for l, t in zip(range(n_lambda), range(n_trial))}\n",
    "\n",
    "for l in range(n_lambda):\n",
    "    t0 = time.time()\n",
    "    print(\"Test distribution with lambda = {:.1f}\".format(lambda_l[l]))\n",
    "    \n",
    "    # compute acceptance probabilities for all sequences (for rejection sampling from test distribution)\n",
    "    paccept_n, logptest_n = assay.get_rejection_sampling_acceptance_probabilities(\n",
    "        seq_n, phitestnuc_lxLxk[l], logptrain_n)\n",
    "\n",
    "    # compute (unnormalized) weights for all data\n",
    "    w_n = np.exp(logptest_n - logptrain_n)\n",
    "\n",
    "    for t in range(n_trial):\n",
    "        \n",
    "        # partition held-out data into calibration data and test data\n",
    "        # (i.e., samples from proposal distribution for rejection sampling from test distribution)\n",
    "        shuffle_idx = np.random.permutation(n)\n",
    "        cal_idx, test_idx = shuffle_idx[: n_cal], shuffle_idx[n_cal :]\n",
    "        \n",
    "        # sample from test distribution using rejection sampling\n",
    "        testsamp_idx = assay.rejection_sample_from_test_distribution(paccept_n[test_idx])\n",
    "        n_test = testsamp_idx.size\n",
    "        if t == 0:\n",
    "            print(\"  On trial 0, sampled {} sequences from the test distribution.\".format(n_test))\n",
    "\n",
    "        # fetch and normalize weights of calibration data\n",
    "        p_sxm1 = np.hstack([np.tile(w_n[cal_idx], [n_test, 1]), w_n[test_idx[testsamp_idx]][:, None]])\n",
    "        p_sxm1 /= np.sum(p_sxm1, axis=1, keepdims=True)\n",
    "        \n",
    "        # compute quantile of weighted calibration scores\n",
    "        augscore_sxm1 = np.tile(np.hstack([score_n[cal_idx], [np.infty]]), (n_test, 1))\n",
    "        q_sx1 = cal.get_weighted_quantile(1 - alpha, p_sxm1.T, augscore_sxm1.T)[:, None]\n",
    "        \n",
    "        # construct confidence intervals\n",
    "        testpred_sx1 = pred_n[test_idx[testsamp_idx]][:, None]\n",
    "        lu_sx2 =  np.hstack([testpred_sx1 - q_sx1, testpred_sx1 + q_sx1])\n",
    "         \n",
    "        # record confidence interval lengths, true fitnesses, and empirical coverage\n",
    "        avglen_lxt[l, t] = np.mean(2 * q_sx1)\n",
    "        len_lxt[(l, t)] = 2 * q_sx1.flatten()\n",
    "        fit_lxt[(l, t)] = y_n[test_idx[testsamp_idx]]\n",
    "        cov_lxt[l, t] = cal.get_split_coverage(lu_sx2, fit_lxt[(l, t)])\n",
    "        \n",
    "    print(\"  Empirical coverage{:.4f}, average length {:.2f} ({:.1f} s)\".format(\n",
    "        np.mean(cov_lxt[l]), np.mean(avglen_lxt[l]), time.time() - t0))\n",
    "    \n",
    "    # save after each lambda\n",
    "    np.savez('../aav/split-results.npz',\n",
    "        cov_lxt=cov_lxt, avglen_lxt=avglen_lxt, len_lxt=len_lxt, fit_lxt=fit_lxt,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-2.1.0",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
